\relax 
\providecommand\zref@newlabel[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{npg-27-373-2020}
\citation{DBLP:journals/corr/VaswaniSPUJGKP17}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{4}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Theory}{4}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}The Lorenz System}{4}{subsection.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The Lorenz attractor for $\sigma = 10$, $\rho = 28$, and $\beta = \frac  {8}{3}$. Generated with RK4 method for 100 time units}}{4}{figure.1}\protected@file@percent }
\newlabel{fig:lorenz_attractor}{{1}{4}{The Lorenz attractor for $\sigma = 10$, $\rho = 28$, and $\beta = \frac {8}{3}$. Generated with RK4 method for 100 time units}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Neural Networks}{5}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}RNNs}{6}{subsection.2.3}\protected@file@percent }
\citation{DBLP:journals/corr/VaswaniSPUJGKP17}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces https://www.deeplearningbook.org/contents/rnn.html}}{7}{figure.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces http://cs231n.stanford.edu/slides/2017/cs231n\_2017\_lecture10.pdf}}{8}{figure.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Transformers}{8}{subsection.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Taken from "All you need is attention" by Google.}}{9}{figure.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Reservoir Computing and Echo State Networks}{9}{subsection.2.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Echo State Network architecture (image taken from the reservoirpy user guide docs).}}{10}{figure.5}\protected@file@percent }
\newlabel{fig:esn}{{5}{10}{Echo State Network architecture (image taken from the reservoirpy user guide docs)}{figure.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Method}{11}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Generating Data}{11}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Setting up the RNN}{12}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Setting up the Transformers Model}{13}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Setting up the RC-ESN}{13}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Hyperparameter optimization process}{13}{subsection.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{15}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Lorenz attractor}{15}{subsection.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces RNN}}{15}{figure.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces ESN}}{15}{figure.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Transformers}}{15}{figure.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Trajectory}{15}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Mean Squared Error}{15}{subsection.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces RNN path(true path is red, model path is blue)}}{16}{figure.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces ESN path(true path is red, model path is blue)}}{17}{figure.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Transformers path(true path is red, model path is blue)}}{18}{figure.11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces RNN MSE}}{19}{figure.12}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces ESN MSE}}{19}{figure.13}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{19}{section.5}\protected@file@percent }
\citation{npg-27-373-2020}
\citation{cite-key}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Transformers MSE}}{20}{figure.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Conclusion}{20}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {A}Code snippets}{21}{appendix.A}\protected@file@percent }
\newlabel{appendix:code}{{A}{21}{Code snippets}{appendix.A}{}}
\newlabel{rk4:lorenz}{{1}{21}{RK4 implementation}{lstlisting.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}RK4 implementation}{21}{lstlisting.1}\protected@file@percent }
\newlabel{datasplit}{{2}{21}{get\_training\_data.py}{lstlisting.2}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2}get\_training\_data.py}{21}{lstlisting.2}\protected@file@percent }
\newlabel{lstm}{{3}{22}{LSTM RNN implementation}{lstlisting.3}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3}LSTM RNN implementation}{22}{lstlisting.3}\protected@file@percent }
\newlabel{inverse:normalization}{{4}{23}{inverse normalization}{lstlisting.4}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {4}inverse normalization}{23}{lstlisting.4}\protected@file@percent }
\newlabel{training:loop}{{5}{23}{Training loop}{lstlisting.5}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5}Training loop}{23}{lstlisting.5}\protected@file@percent }
\newlabel{transformer}{{6}{24}{Transformer implementation}{lstlisting.6}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {6}Transformer implementation}{24}{lstlisting.6}\protected@file@percent }
\newlabel{positional:encoding}{{7}{25}{Positional encoding implementation}{lstlisting.7}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7}Positional encoding implementation}{25}{lstlisting.7}\protected@file@percent }
\newlabel{reservoir}{{8}{25}{ESN implementation}{lstlisting.8}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {8}ESN implementation}{25}{lstlisting.8}\protected@file@percent }
\newlabel{true:loss}{{9}{26}{true\_loss.py}{lstlisting.9}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {9}true\_loss.py}{26}{lstlisting.9}\protected@file@percent }
\bibstyle{apalike}
\bibdata{references}
\bibcite{npg-27-373-2020}{Chattopadhyay et\nobreakspace  {}al., 2020}
\bibcite{cite-key}{Gauthier et\nobreakspace  {}al., 2021}
\bibcite{DBLP:journals/corr/VaswaniSPUJGKP17}{Vaswani et\nobreakspace  {}al., 2017}
\gdef \@abspage@last{27}
